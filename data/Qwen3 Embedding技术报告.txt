# Qwen3 Embedding：通过基础模型推进文本嵌入和重排序
### arXiv:2506.05176v3 [cs.CL] 2025年6月11日
### 技术报告

**Qwen3 Embedding：通过基础模型推进文本嵌入和重排序**

张岩昭* 李明鑫* 龙丁坤* 张鑫* 林欢 杨宝松 谢鹏军 杨安 刘大一恒 林俊阳 黄飞 周景仁 阿里巴巴集团通义实验室

https://huggingface.co/Qwen

https://modelscope.cn/organization/qwen

https://github.com/QwenLM/Qwen3-Embedding

### 摘要
在这项工作中，我们介绍了Qwen3 Embedding系列，它基于Qwen3基础模型，在文本嵌入和重排序能力上较其前身GTE-Qwen系列有显著提升。利用Qwen3大语言模型在多语言文本理解和生成方面的强大能力，我们创新的多阶段训练流程将大规模无监督预训练与高质量数据集上的有监督微调相结合。有效的模型合并策略进一步确保了Qwen3 Embedding系列的鲁棒性和适应性。在训练过程中，Qwen3大语言模型不仅作为骨干模型，还在跨多个领域和语言合成高质量、丰富多样的训练数据方面发挥关键作用，从而增强了训练流程。Qwen3 Embedding系列提供了一系列模型规模（0.6B、4B、8B），用于嵌入和重排序任务，满足不同的部署场景，用户可以针对效率或效果进行优化。实证评估表明，Qwen3 Embedding系列在各种基准测试中取得了最先进的结果。值得注意的是，它在多语言评估基准MTEB上的文本嵌入任务，以及各种检索任务（包括代码检索、跨语言检索和多语言检索）中表现出色。为了促进可重复性并推动社区驱动的研究与开发，Qwen3 Embedding模型在Apache 2.0许可证下公开提供。

### 1 引言
文本嵌入和重排序是许多自然语言处理和信息检索应用的基本组成部分，包括网页搜索、问答系统、推荐系统等（Karpukhin等人，2020；Huang等人，2020；Zhao等人，2023；2024）。高质量的嵌入使模型能够捕捉文本之间的语义关系，而有效的重排序机制确保最相关的结果被优先考虑。最近，在大型语言模型（如Qwen3（Yang等人，2025）、GPT-4o（Hurst等人，2024））的推动下，新兴的应用范式如检索增强生成（RAG）和代理系统，对文本嵌入和重排序在模型训练范式和应用场景方面都提出了新的要求和挑战。尽管取得了显著进展，但训练在可扩展性、上下文理解以及与特定下游任务对齐方面表现良好的嵌入和重排序模型仍然具有挑战性。

大型语言模型（LLM）的出现显著推进了文本嵌入和重排序模型的发展。在LLM引入之前，主要方法是使用仅编码器的预训练语言模型（如BERT）作为训练的基础模型（Reimers & Gurevych，2019）。LLM固有的更丰富的世界知识、文本理解和推理能力，导致在这些架构上训练的模型进一步增强。此外，已有大量研究促进了LLM在训练数据合成和高质量数据过滤等过程中的集成（Wang等人，2024；Lee等人，2024；2025b）。LLM的基本特征还启发了新训练范式的引入。例如，在嵌入模型训练过程中，结合跨指令类型、领域和语言等方面的差异化任务，已在下游任务中产生了更好的性能（Su等人，2023）。同样，对于重排序模型训练，通过基于用户提示的零样本方法和结合有监督微调的方法都实现了进展（Ma等人，2023；Pradeep等人，2023；Zhang等人，2024a；Zhuang等人，2024）。

在这项工作中，我们介绍了构建在Qwen3基础模型之上的Qwen3 Embedding系列模型。Qwen3基础模型同时发布了基础版和指令版模型，我们利用这些模型强大的多语言文本理解和生成能力，充分发挥它们在训练嵌入和重排序模型中的潜力。为了训练嵌入模型，我们实现了一个多阶段训练流程，包括大规模无监督预训练，然后在高质量数据集上进行有监督微调。我们还采用了与各种模型检查点的模型合并，以增强鲁棒性和泛化能力。Qwen3指令模型允许高效合成大规模、高质量、多语言和多任务的文本相关性数据集。这种合成数据用于初始的无监督训练阶段，而选择高质量、小规模的数据子集用于第二阶段的有监督训练。对于重排序模型，我们采用类似的两阶段训练方案，包括高质量有监督微调和模型合并阶段。基于Qwen3骨干模型的不同规模（包括0.6B、4B和8B），我们最终训练了三个文本嵌入模型和三个文本重排序模型。为了促进它们在下游任务中的应用，Qwen3 Embedding系列支持几个实用功能，如嵌入模型的灵活维度表示，以及嵌入和重排序模型的可定制指令。

我们在跨越多个任务和领域的综合基准上评估了Qwen3 Embedding系列。实验结果表明，我们的嵌入和重排序模型取得了最先进的性能，在几个检索任务中与领先的专有模型具有竞争力。例如，旗舰模型Qwen3-8B-Embedding在MTEB多语言基准（Enevoldsen等人，2025）上获得70.58分，在MTEB代码基准（Enevoldsen等人，2025）上获得80.68分，超过了之前最先进的专有嵌入模型Gemini-Embedding（Lee等人，2025b）。此外，我们的重排序模型在一系列检索任务中提供了有竞争力的结果。Qwen3-Reranker-0.6B模型在许多检索任务中超过了以前的顶级模型，而更大的Qwen3-Reranker-8B模型表现出甚至更优越的性能，在多个任务上比0.6B模型的排名结果提高了3.0分。此外，我们包括一个建设性的消融研究，以阐明促成Qwen3 Embedding系列卓越性能的关键因素，提供对其有效性的见解。

在以下部分中，我们描述模型架构的设计，详细说明训练过程，呈现Qwen3 Embedding系列的嵌入和重排序模型的实验结果，并通过总结关键发现和概述未来研究的潜在方向来结束本技术报告。

### 2 模型架构
嵌入和重排序模型的核心思想是以任务感知的方式评估相关性。给定查询q和文档d，嵌入和重排序模型基于指令I定义的相似性标准评估它们的相关性。为了使模型能够进行任务感知的相关性估计，训练数据通常组织为{I_i, q_i, d_i^+, d_i,1^-, ..., d_i,n^-}，其中d_i^+表示查询q_i的正（相关）文档，d_i,j^-是负（不相关）文档。在不同的文本对上训练模型，拓宽了其对一系列下游任务的适用性，包括检索、语义文本相似性、分类和聚类。

**架构**：Qwen3嵌入和重排序模型构建在Qwen3基础模型的密集版本上，有三种规模：0.6B、4B和8B参数。我们使用Qwen3基础模型初始化这些模型，以利用它们在文本建模和指令遵循方面的能力。每个模型配置的模型层、隐藏大小和上下文长度在表1中详细说明。

**嵌入模型**：对于文本嵌入，我们使用具有因果注意力的LLM，在输入序列的末尾附加一个[EOS]标记。最终的嵌入来自对应于该[EOS]标记的最后一层的隐藏状态。

为了确保嵌入在下游任务中遵循指令，我们将指令和查询连接成一个单一的输入上下文，而在使用LLM处理之前，文档保持不变。查询的输入格式如下：
{指令} {查询}<|endoftext|>

**重排序模型**：为了更准确地评估文本相似性，我们在单个上下文中使用LLM进行点式重排序。与嵌入模型类似，为了实现指令遵循能力，我们在输入上下文中包括指令。我们使用LLM聊天模板，并将相似性评估任务构建为二元分类问题。LLM的输入遵循如下模板：
<|im_start|>system
根据提供的查询和指令，判断文档是否符合要求。注意，答案只能是“是”或“否”。<|im_end|>
￫ <|im_start|>user
<Instruct>: {指令}
<Query>: {查询}
<Document>: {文档}<|im_end|>
<|im_start|>assistant
<|FunctionCallBegin|>\n\n</think>\n\n

为了根据给定的输入计算相关性分数，我们评估下一个标记为“是”或“否”的可能性。这用数学表达式表示为：
\[score(q, d)=\frac{e^{P(yes | I, q, d)}}{e^{P(yes | I, q, d)}+e^{P(no | I, q, d)}}\]

### 3 模型训练
在本节中，我们描述所采用的多阶段训练流程，并呈现此训练方法的关键要素，包括训练目标、训练数据合成和高质量训练数据的过滤。

#### 3.1 训练目标
在介绍我们的训练流程之前，我们首先概述训练过程中嵌入和重排序模型使用的优化损失函数。对于嵌入模型，我们利用基于InfoNCE框架（Oord等人，2018）的改进对比损失。给定一批N个训练实例，损失定义为：
\[L_{embedding }=-\frac{1}{N} \sum_{i}^{N} log \frac{e^{\left(s\left(q_{i}, d_{i}^{+}\right) / \tau\right)}}{Z_{i}}, (1)\]
其中s(·, ·)是相似性函数（我们使用余弦相似性），τ是温度参数，Z_i是归一化因子，它聚合了正面对与各种负面对的相似性分数：
\[Z_{i}=e^{\left(s\left(q_{i}, d_{i}^{+}\right) / \tau\right)}+\sum_{k}^{K} m_{i k} e^{\left(s\left(q_{i}, d_{i, k}^{-}\right) / \tau\right)}+\sum_{j \neq i} m_{i j} e^{\left(s\left(q_{i}, q_{j}\right) / \tau\right)}+\sum_{j \neq i} m_{i j} e^{\left(s\left(d_{i}^{+}, d_{j}\right) / \tau\right)}+\sum_{j \neq i} m_{i j} e^{\left(s\left(q_{i}, d_{j}\right) / \tau\right)}\]

其中这些项表示与以下的相似性：(1) 正文档d_i^+，(2) K个硬负例d_i,k^-，(3) 其他批内查询q_j，(4) 与正文档d_i^+比较的其他批内文档d_j，(5) 与查询q_i比较的其他批内文档d_j。掩码因子m_ij旨在减轻假负例的影响，定义为：
\[m_{i j}= \begin{cases}0 & if s_{i j}>s\left(q_{i}, d_{i}^{+}\right)+0.1 或 d_{j}==d_{i}^{+}, \\ 1 & 否则, \end{cases}\]
其中s_ij是q_i, d_j或q_i, q_j的相应分数。

对于重排序模型，我们优化定义为的监督微调（SFT）损失：
\[L_{reranking }=-log p(l | \mathcal{P}(q, d)), (2)\]
其中p(·|*)表示LLM分配的概率。标签l对于正文档是“是”，对于负文档是“否”。这个损失函数鼓励模型为正确标签分配更高的概率，从而提高排序性能。

#### 3.2 多阶段训练
多阶段训练方法是训练文本嵌入模型的常见实践（Li等人，2023；Wang等人，2022；Chen等人，2024）。这种策略通常从在包含噪声的大规模半监督数据上的初始训练开始，然后使用较小的高质量监督数据集进行微调。这个两步过程增强了嵌入模型的性能和泛化能力。大规模弱监督训练数据对模型的泛化做出了重大贡献，而后续阶段用高质量数据进行微调进一步提高了模型性能。嵌入模型的两个训练阶段都使用方程1中定义的优化目标，而重排序模型训练采用方程2中定义的损失函数作为优化目标。

在现有多阶段训练框架的基础上，Qwen3 Embedding系列引入了以下关键创新：

- **大规模合成数据驱动的弱监督训练**：与以前的工作（如GTE、E5、BGE模型）不同，其中弱监督训练数据主要从开源社区（如问答论坛或学术论文）收集，我们提出利用基础模型的文本理解和生成能力直接合成对数据。这种方法允许在合成提示中任意定义所需对数据的各种维度，如任务、语言、长度和难度。与从开放域来源收集数据相比，基础模型驱动的数据合成提供了更大的可控性，能够精确管理生成数据的质量和多样性，特别是在低资源场景和语言中。

- **监督微调中高质量合成数据的利用**：由于Qwen3基础模型的卓越性能，合成数据的质量显著提高。因此，在第二阶段的监督训练中，选择性地合并这种高质量合成数据进一步增强了整体模型性能和泛化能力。

- **模型合并**：受先前工作（Li等人，2024）的启发，在完成监督微调后，我们应用了基于球面线性插值（slerp）的模型合并技术。该技术涉及合并在微调过程中保存的多个模型检查点。此步骤旨在提高模型在各种数据分布上的鲁棒性和泛化性能。

值得注意的是，重排序模型的训练过程不包括第一阶段的弱监督训练阶段。

#### 3.3 合成数据集
为了创建用于在各种相似性任务上训练模型的强大合成数据集，我们生成跨越检索、双语挖掘、分类和语义文本相似性（STS）等类别的多样化文本对。这些合成数据对的质量通过使用Qwen3 32B模型作为数据合成的基础模型来确保。我们设计了多样化的提示策略来提高生成数据的多样性和真实性。例如，在文本检索任务中，我们使用来自Qwen3的多语言预训练语料库合成数据。在数据合成过程中，为每个文档分配特定角色，以模拟潜在用户查询该文档的情况。这种用户视角的注入增强了合成查询的多样性和现实性。具体来说，我们使用检索模型从角色库中为每个文档识别前五个角色候选，并将这些文档与其角色候选一起呈现给提示。这指导模型输出最适合查询生成的角色配置。此外，提示包含各种维度，如查询类型（如关键字、事实、摘要、判断）、查询长度、难度和语言。这种多维方法确保了合成数据的质量和多样性。

最后，我们创建了总共约1.5亿对多任务弱监督训练数据。我们的实验表明，用这些合成数据训练的嵌入模型在下游评估中表现异常出色，特别是在MTEB多语言基准中超过了许多以前的监督模型。这促使我们过滤合成数据以识别高质量对，以纳入第二阶段的监督训练。我们采用简单的余弦相似性计算来选择数据对，从随机采样的数据中保留余弦相似性大于0.7的对。最终，选择了约1200万高质量监督训练数据对用于进一步训练。

### 4 评估
我们在多个基准上进行全面和公平的评估，以评估Qwen3 Embedding模型的能力。

#### 4.1 设置
对于文本嵌入模型，我们使用大规模多语言文本嵌入基准（MMTEB）（Enevoldsen等人，2025）进行评估。MMTEB是MTEB（Muennighoff等人，2023）的大规模社区驱动扩展，涵盖超过500个质量控制的评估任务，跨越超过250种语言。除了经典的文本任务，如各种检索、分类和语义文本相似性之外，MMTEB还包括一系列具有挑战性的新任务，如指令遵循、长文档检索和代码检索，代表了迄今为止嵌入模型最大的多语言评估任务集合。我们的MMTEB评估包括216个单独的评估任务，由131个MTEB（多语言）任务（Enevoldsen等人，2025）、41个MTEB（英语，v2）任务（Muennighoff等人，2023）、32个CMTEB任务（Xiao等人，2024）和12个MTEB（代码）代码检索任务（Enevoldsen等人，2025）组成。

此外，我们选择了一系列文本检索任务来评估我们模型的文本重排序能力。我们探索了三种类型的检索任务：(1) 基本相关性检索，分为英语、中文和多语言，分别在MTEB（Muennighoff等人，2023）、CMTEB（Xiao等人，2024）、MMTEB（Enevoldsen等人，2025）和MLDR（Chen等人，2024）上评估；(2) 代码检索，在MTEB-Code（Enevoldsen等人，2025）上评估，该基准仅包含与代码相关的检索数据；(3) 复杂指令检索，在FollowIR（Weller等人，2024）上评估。

**比较方法**：我们将我们的模型与最著名的开源文本嵌入模型和商业API服务进行比较。开源模型包括GTE（Li等人，2023；Zhang等人，2024b）、E5（Wang等人，2022）和BGE（Xiao等人，2024）系列，以及NVEmbed-v2（Lee等人，2025a）、GritLM-7B Muennighoff等人（2025）。评估的商业API包括OpenAI的text-embedding-3-large、谷歌的Gemini-embedding和Cohere的cohere-embed-multilingual-v3.0。对于重排序，我们与jina1、mGTE（Zhang等人，2024b）和BGE-m3（Chen等人，2024）的重排序器进行比较。

#### 4.2 主要结果
**嵌入**：在表2中，我们呈现了在MMTEB（Enevoldsen等人，2025）上的评估结果，该基准全面涵盖了多种语言的广泛嵌入任务。我们的Qwen3-Embedding-4B/8B模型取得了最佳性能，而我们最小的模型Qwen3-Embedding-0.6B尽管只有0.6B参数，仅落后于表现最佳的基线方法（Gemini-Embedding）。在表3中，我们呈现了在MTEB（英语，v2）（Muennighoff等人，2023）、CMTEB（Xiao等人，2024）和MTEB（代码）（Enevoldsen等人，2025）上的评估结果。分数反映了与MMTEB相似的趋势，我们的Qwen3-Embedding-4B/8B模型始终优于其他模型。值得注意的是，Qwen3-Embedding-0.6B模型排名仅次于Gemini-Embedding，同时与gte-Qwen2-7B-instruct具有竞争力。

**重排序**：在表4中，我们呈现了各种重排序任务的评估结果（§4.1）。我们使用Qwen3-Embedding-0.6B模型检索前100个候选，然后应用不同的重排序模型进行进一步优化。这种方法确保了重排序模型的公平评估。我们的结果表明，所有三个Qwen3-Reranker模型与嵌入模型相比都提高了性能，并且超过了所有基线重排序方法，其中Qwen3-Reranker-8B在大多数任务中取得了最高性能。

#### 4.3 分析
为了进一步分析和探索Qwen3 Embedding模型训练框架的关键要素，我们从以下维度进行分析：

**大规模弱监督预训练的有效性**：我们首先分析嵌入模型大规模弱监督训练阶段的有效性。如表5所示，仅在合成数据上训练的Qwen3-Embedding-0.6B模型（没有后续训练阶段，如第一行所示）与最终的Qwen3-Embedding-0.6B模型（如最后一行所示）相比，取得了合理且强大的性能。如果我们进一步移除弱监督训练阶段（即没有合成数据训练，如第二行所示），最终性能明显下降。这表明大规模弱监督训练阶段对于取得优异性能至关重要。

**模型合并的有效性**：接下来，我们比较模型合并阶段引起的性能差异。如表5所示，没有使用模型合并技术训练的模型（第三行，使用数据采样来平衡各种任务）比最终的Qwen3-Embedding-0.6B模型（使用模型合并，如最后一行所示）表现差得多。这表明模型合并阶段对于开发强大的模型也很关键。

### 5 结论
在本技术报告中，我们介绍了Qwen3-Embedding系列，这是一套基于Qwen3基础模型的全面文本嵌入和重排序模型。这些模型旨在在广泛的文本嵌入和重排序任务中表现出色，包括多语言检索、代码检索和复杂指令遵循。Qwen3-Embedding模型建立在强大的多阶段训练流程之上，该流程将合成数据上的大规模弱监督预训练与高质量数据集上的有监督微调和模型合并相结合。Qwen3 LLM在跨多种语言和任务合成多样化训练数据方面发挥关键作用，从而增强了模型的能力。我们的综合评估表明，Qwen3-Embedding模型在各种基准上取得了最先进的性能，包括MTEB、CMTEB、MMTEB和几个检索基准。我们很高兴开源Qwen3-Embedding和Qwen3-Reranker模型（0.6B、4B和8B），使社区能够使用和构建它们。

### 参考文献
[参考文献部分略，保留原文格式]

### A 附录
#### A.1 合成数据
我们构建了四种类型的合成数据——检索、双语挖掘、语义文本相似性和分类，以使模型在预训练期间适应各种相似性任务。为了确保多语言和跨语言的多样性，数据使用Qwen3 32B生成。下面是一个合成检索文本对的示例。检索数据使用文档到查询的方法合成。我们从Qwen3基础模型的预训练语料库中收集多语言语料库作为文档源。然后应用两阶段生成流程，包括：(1) 配置和 (2) 查询生成。在配置阶段，我们使用大型语言模型（LLM）确定合成查询的“问题类型”、“难度”和“角色”。候选角色从Persona Hub（Ge等人，2024）中检索，选择与给定文档最相关的前五个。此步骤旨在增强生成查询的多样性。使用的模板如下：

给定一个**段落**和**角色**，从三个字段：角色、问题类型、难度中选择合适的选项，并以JSON格式返回输出。
￫ 首先，从候选者中选择可能对段落感兴趣的**角色**。然后选择角色可能针对段落提出的**问题类型**；最后，根据段落、角色和问题类型选择可能问题的**难度**。
￫
角色：由输入**角色**给出
问题类型：- 关键字：...
- 获取知识：...
- 摘要：...
- 是或否：...
- 背景：...
难度：- 高中：...
- 大学：... - 博士：...
这里有一些例子<Example1> <Example2> <Example3>
现在，根据用户的**段落**和**角色**生成**输出**，**段落**将是{语言}语言，**角色**将是英语。
￫ 确保仅生成内容为英语的JSON输出。
**段落**：{段落} **角色**：{角色}

在查询生成阶段，我们使用第一阶段选择的配置来指导查询的生成。此外，我们明确指定生成查询的所需长度和语言。使用的模板如下：

给定一个**角色**、**段落**和**要求**，从**角色**的角度生成一个满足**要求**并可用于检索**段落**的查询。请以JSON格式返回结果。
￫
这里有一个例子：<example>
现在，根据**角色**、**段落**和语言生成**输出**，**角色**和**要求**将是英语。用户的**要求**，**段落**将是{corpus_language}
￫ 确保仅生成JSON输出，键为英语，值为{queries_language}语言。
**角色**
{角色}
**段落** {段落}
**要求**
- 类型：{类型}；- 难度：{难度}；
- 长度：生成的句子长度应为{长度}个单词；
- 语言：生成结果的语言应为{语言}语言；

| 阶段 | 数据集大小 |
| --- | --- |
| 弱监督预训练 | 合成数据 ~1.5亿 |
|  | MS MARCO、NQ、HotpotQA、NLI、Dureader、T2-Ranking、SimCLUE、 |
|  | MIRACL、MLDR、Mr.TyDi、 |
|  | Multi-CPR、CodeSearchNet等 |
|  | + 高质量合成数据 |
|  | 合成数据：~1200万 标记数据：~700万 |
| 有监督微调 |  |