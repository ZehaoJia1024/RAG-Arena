{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG\n",
    "在这篇notebook中，我们将实现一个标准的RAG流程，并且评估标准RAG算法的性能。\n",
    "标准RAG一共分为三个流程，检索（Retrieval, R）、增强（Augmented, A）、生成（Generation, G）。\n",
    "- **检索**：使用嵌入模型，根据问题检索文档中的多个相关文本块。\n",
    "- **增强**：拼接上下文信息，增强信息的表达。\n",
    "- **生成**：根据上下文信息生成回复。\n",
    "\n",
    "RAG是由 **Facebook AI Research（现 Meta AI）** 的一个团队在一篇名为 《**Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks**》的论文中正式提出的。\n",
    "> https://arxiv.org/abs/2005.11401\n",
    "\n",
    "其核心特点是 端到端的可微调。这意味着检索器（Retriever）和生成器（Generator）被视为一个统一的、可以共同训练的系统。\n",
    "如今我们谈论的RAG，是一种更加模块化和实用化的架构。\n",
    "- 检索器: 通常是一个独立的向量数据库和嵌入模型，它的任务只有一个：根据查询返回最相关的文本块。\n",
    "- 生成器: 通常是一个强大的、通用的、预训练好的LLM。\n",
    "\n",
    "![](figures/01%20RAG/流程图.png)\n",
    "\n",
    "接下来，我们开始对标准的RAG进行评估。"
   ],
   "id": "c764321d67b9505c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "首先需要导入相关的代码库。",
   "id": "a039458e9ce201f5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-01T15:06:53.667850Z",
     "start_time": "2025-07-01T15:06:33.237083Z"
    }
   },
   "source": [
    "from rag_evaluate import Embedder, LLMJudge, load_data, ReplyModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略所有的警告"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\anaconda3\\envs\\main\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "加载评估的相关数据。",
   "id": "43971e17321b52f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T15:06:53.683545Z",
     "start_time": "2025-07-01T15:06:53.670519Z"
    }
   },
   "cell_type": "code",
   "source": "documents, QA = load_data(data_dir='data')",
   "id": "c2d3be25271f11e7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在进行RAG前，首先要将文档进行分块。\n",
    "原因如下：\n",
    "1. 如果文档太长，嵌入模型难以处理。\n",
    "2. 一个完整的文档中，可能只有部分语句是与问题相关的，因此需要对文档进行切块。\n",
    "3. LLM尽量避免输入太长的token，输入token太长容易造成无法抓住重点。\n",
    "\n",
    "我们使用最简单的分块策略，即按照自然段进行划分。\n",
    "在划分时，需要指定一个 `chunk_size`，用于指定每一个文本模块的大小。\n",
    "文本块太短容易造成信息不充分。\n",
    "文本块太长容易造成信息的冗余。\n",
    "在下面的代码中，有些自然段的长度可能超过chunk_size，这些内容暂时不做处理。我们只对长度较短的自然段进行拼接。"
   ],
   "id": "199c3d59066bdbbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T15:06:53.698536Z",
     "start_time": "2025-07-01T15:06:53.684545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk_documents(documents, chunk_size):\n",
    "    chunks = []\n",
    "    for document in documents:\n",
    "        # 按段落分割，并过滤掉空段落\n",
    "        paragraphs = [p.strip() for p in document.split(\"\\n\") if p.strip()]\n",
    "\n",
    "        current_chunk = \"\"\n",
    "        for i, paragraph in enumerate(paragraphs):\n",
    "            current_chunk += paragraph\n",
    "            if len(current_chunk) >= chunk_size:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = \"\"\n",
    "    \n",
    "    return chunks"
   ],
   "id": "e36504983106702c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "指定文本块的最小长度为512，并提取所有的问题与正确答案。",
   "id": "e4695e37b93eccd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T15:06:53.713519Z",
     "start_time": "2025-07-01T15:06:53.700523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks = chunk_documents(documents, 512)\n",
    "queries = [qa[\"question\"] for qa in QA['data']]\n",
    "answers_gt = [qa[\"answer\"] for qa in QA['data']]"
   ],
   "id": "9739f39dd3daf7bf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "加载向量化工具，并对所有的**文本块**和**问题**进行向量化。",
   "id": "92898095e6f68844"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T15:08:21.773935Z",
     "start_time": "2025-07-01T15:06:53.717540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedder = Embedder()\n",
    "chunk_embeddings = embedder.embed(chunks)\n",
    "query_embeddings = embedder.embed(queries)"
   ],
   "id": "7f35efb570761a90",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "接下来，计算所有问题与所有文本块之间的相似度矩阵。\n",
    "\n",
    "通过相似度矩阵，我们可以找到每个**问题**与每个**文本块**之间的**相似度**，从而找到某一个问题与哪些文本块存在着关联。\n",
    "\n",
    "在这里，我们需要指定一个`k值`，通过k值确定需要的文本块数量。\n",
    "\n",
    "若k值太大，会造成文本模块过多，引入无关文本块，同时会造成输入token数量的爆炸💥。\n",
    "\n",
    "若K值太小，则会导致信息量的缺失，可能无法找到相关的文本块。\n",
    "\n",
    "在代码中，我们将得到每个问题相关文本块的索引（`top_k_indices`），后续可以通过索引找到相关的文本块。"
   ],
   "id": "b0310e225fab04c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T15:08:21.896851Z",
     "start_time": "2025-07-01T15:08:21.775935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similarity = embedder.similarity(query_embeddings, chunk_embeddings)\n",
    "k = 3\n",
    "top_k_indices = embedder.get_top_k(similarity, k)"
   ],
   "id": "1bef48b9f428b2cd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在检索到相关的文本块后，需要使用LLM进行回复。\n",
    "\n",
    "相关的提示词模板为：\n",
    "系统提示词为：\n",
    "```\n",
    "你是一个问答机器人。请严格根据下面提供的“参考文档”来回答问题。\n",
    "如果文档中的信息不足以回答，直接回复“根据提供的文档，我无法回答该问题。”\n",
    "```\n",
    "\n",
    "用户提示词为：\n",
    "```\n",
    "参考文档:\n",
    "---\n",
    "{context_str}\n",
    "---\n",
    "\n",
    "问题: {query}\n",
    "```"
   ],
   "id": "daf7893b9e5b2ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T15:08:45.740014Z",
     "start_time": "2025-07-01T15:08:21.900876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ReplyModel()\n",
    "answers = []\n",
    "for i, query in enumerate(queries):\n",
    "    retrieved_chunks = []\n",
    "    for doc_idx in top_k_indices[i]:\n",
    "        retrieved_chunks.append(chunks[doc_idx])\n",
    "        \n",
    "    answer = llm.answer(query, retrieved_chunks)\n",
    "    answers.append(answer)\n",
    "    print(query)\n",
    "    print(answer)\n",
    "    print(\"=\" * 30)"
   ],
   "id": "1810d1a8e7c7f882",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在后训练过程中，为什么Qwen3模型在经过“思考模式融合”和“通用RL”阶段后，在AIME’24和LiveCodeBench等具有挑战性的任务上性能反而有所下降？\n",
      "根据提供的文档，Qwen3模型在经过“思考模式融合”和“通用RL”阶段后，在AIME’24和LiveCodeBench等具有挑战性的任务上性能下降的原因是：模型在更广泛的通用任务上训练，这可能损害了其处理复杂问题的专业能力。文档中提到，这种退化是由于模型在更广泛的通用任务上训练，可能影响了其处理复杂问题的专业能力，因此选择接受这种性能权衡以增强模型的整体多功能性。\n",
      "==============================\n",
      "在针对轻量级模型的“强到弱蒸馏”管道中，在线蒸馏（Online Distillation）阶段的具体实现方式是什么？\n",
      "根据提供的文档，\"强到弱蒸馏\"管道分为两个主要阶段：（1）离线蒸馏和（2）在线训练。然而，文档中并未详细说明在线蒸馏（Online Distillation）阶段的具体实现方式。因此，无法提供在线蒸馏阶段的具体实现方式。\n",
      "==============================\n",
      "Qwen3的开发团队在预训练数据筛选和模型后训练阶段，具体实施了哪些伦理审查（Ethical Review）流程来确保模型的安全性并减少偏见？\n",
      "根据提供的文档，我无法回答该问题。文档中未提及Qwen3的开发团队在预训练数据筛选和模型后训练阶段具体实施了哪些伦理审查（Ethical Review）流程来确保模型的安全性并减少偏见。\n",
      "==============================\n",
      "与Qwen2.5-MoE相比，Qwen3的MoE模型在架构设计上引入了哪些关键的改变？\n",
      "与Qwen2.5-MoE相比，Qwen3的MoE模型在架构设计上引入了以下关键的改变：\n",
      "\n",
      "1. **移除了共享专家**：Qwen3-MoE设计中不包含共享专家，而Qwen2.5-MoE则包含共享专家。\n",
      "\n",
      "2. **细粒度专家分割**：Qwen3-MoE实现了细粒度专家分割，这是基于Dai等人（2024）的工作。\n",
      "\n",
      "3. **全局批处理负载平衡损失**：Qwen3-MoE采用了全局批处理负载平衡损失（Qiu等人，2025），以促进专家专业化。\n",
      "\n",
      "4. **激活参数的优化**：实验结果表明，Qwen3 MoE基础模型仅使用1/5的激活参数即可实现与Qwen3密集型基础模型相似的性能，并且可以使用更少的激活参数和总参数超越Qwen2.5 MoE基础模型。这表明Qwen3 MoE在训练和推理成本方面具有显著优势。\n",
      "==============================\n",
      "在“思考模式融合”阶段，Qwen3模型是如何通过显式训练（explicitly trained）来学习并实现“思考预算（Thinking Budget）”这一能力的？\n",
      "根据提供的文档，Qwen3模型的“思考预算（Thinking Budget）”能力并不是通过显式训练（explicitly trained）来学习的，而是应用思考模式融合的自然结果。文档中提到：“这种能力不是显式训练的，而是应用思考模式融合的自然结果。”因此，Qwen3模型在“思考模式融合”阶段是通过非显式训练的方式实现了“思考预算”这一能力的。\n",
      "==============================\n",
      "相较于以往的多阶段训练框架（如GTE、E5），Qwen3 Embedding系列在训练流程中引入了哪三项关键创新？\n",
      "Qwen3 Embedding系列在训练流程中引入了以下三项关键创新：\n",
      "\n",
      "1. **大规模合成数据驱动的弱监督训练**：与以往从开源社区收集弱监督训练数据不同，Qwen3 Embedding系列利用基础模型的文本理解和生成能力直接合成对数据，提供了更大的可控性，能够精确管理生成数据的质量和多样性。\n",
      "\n",
      "2. **监督微调中高质量合成数据的利用**：在第二阶段的监督训练中，选择性地合并高质量合成数据，进一步增强了整体模型性能和泛化能力。\n",
      "\n",
      "3. **模型合并**：在完成监督微调后，应用基于球面线性插值（slerp）的模型合并技术，合并在微调过程中保存的多个模型检查点，以提高模型在各种数据分布上的鲁棒性和泛化性能。\n",
      "==============================\n",
      "Qwen3的重排序模型和嵌入模型采用了相同的两阶段训练流程，请解释在第一阶段的弱监督训练中，重排序模型是如何利用合成数据进行优化的？\n",
      "根据提供的文档，Qwen3的重排序模型在第一阶段的弱监督训练中利用合成数据进行优化。具体来说，Qwen3指令模型允许高效合成大规模、高质量、多语言和多任务的文本相关性数据集。这种合成数据用于初始的无监督训练阶段，而选择高质量、小规模的数据子集用于第二阶段的有监督训练。因此，在重排序模型的第一阶段，即弱监督训练阶段，模型通过使用合成数据来优化其性能，这有助于提升模型在后续有监督微调阶段的性能。此外，文档提到重排序模型采用类似的两阶段训练方案，包括高质量有监督微调和模型合并阶段，其中第一阶段的弱监督训练利用了合成数据。\n",
      "==============================\n",
      "请详细描述附录A.1中提到的，为合成检索文本对所采用的两阶段生成流程（配置阶段和查询生成阶段）的具体步骤和目的。\n",
      "{\n",
      "  \"role\": \"英语\",\n",
      "  \"question_type\": \"摘要\",\n",
      "  \"difficulty\": \"大学\"\n",
      "}\n",
      "==============================\n",
      "Qwen3的重排序模型是如何将相似性评估构建为一个分类问题，并最终计算出相关性分数的？请描述其具体机制和数学表达式。\n",
      "Qwen3的重排序模型将相似性评估构建为一个二元分类问题，具体机制如下：\n",
      "\n",
      "1. **输入格式**：重排序模型的输入遵循模板“根据给定的查询和指令，判断文档是否符合要求。注意，答案只能是‘是’或‘否’。”其中，{指令}是任务相关的指令，{查询}是用户提供的查询，{文档}是需要评估的相关文档。\n",
      "\n",
      "2. **任务构建**：模型的任务是判断给定的文档是否符合指令和查询的要求，因此将相似性评估转化为一个二元分类问题，即判断文档是否相关（“是”）或不相关（“否”）。\n",
      "\n",
      "3. **输出计算**：模型输出下一个标记为“是”或“否”的可能性。具体来说，模型计算在给定指令、查询和文档的情况下，下一个标记是“是”的概率 $ P(yes | I, q, d) $ 和是“否”的概率 $ P(no | I, q, d) $。\n",
      "\n",
      "4. **相关性分数计算**：最终的相关性分数通过以下数学表达式计算得出：\n",
      "   $$\n",
      "   score(q, d) = \\frac{e^{P(yes | I, q, d)}}{e^{P(yes | I, q, d)} + e^{P(no | I, q, d)}}\n",
      "   $$\n",
      "   该公式是一个逻辑斯蒂回归函数，将概率转换为0到1之间的分数，表示文档与查询的相关性程度。分数越高，表示文档越符合要求。\n",
      "==============================\n",
      "报告强调了使用Qwen3 32B模型合成大规模训练数据，请问在数据合成过程中，团队遵循了哪些具体的伦理准则或偏见缓解措施来确保生成数据的公平性和无害性？\n",
      "根据提供的文档，没有具体提到在数据合成过程中遵循了哪些伦理准则或偏见缓解措施来确保生成数据的公平性和无害性。因此，无法确定报告中是否涉及相关伦理准则或偏见缓解措施。\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "最后一步，使用另一个性能较强的模型，对答案进行评估。",
   "id": "3c628d757f3142b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T15:13:31.650218Z",
     "start_time": "2025-07-01T15:08:45.741232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "judge = LLMJudge()\n",
    "judge.evaluate(queries, answers_gt, answers)"
   ],
   "id": "5d2c8d6a0f0d298e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 正在评估问题：在后训练过程中，为什么Qwen3模型在经过“思考模式融合”和“通用RL”阶段后，在AIME’24和LiveCodeBench等具有挑战性的任务上性能反而有所下降？\n",
      "--------------------\n",
      "{'scores': {'Correctness': 5, 'Completeness': 4, 'Clarity & Conciseness': 5}, 'reasoning': \"生成答案准确捕捉了正确答案的核心因果关系（通用任务训练损害专业能力），且完整复现了'多功能性权衡'这一关键结论。但在完整性上扣1分，因为未明确提及原文档中'退化'（degradation）这一专业表述，且未具体指明AIME’24和LiveCodeBench这两个任务场景。语言表达简洁流畅，逻辑结构清晰，无冗余信息。\", 'final_score': 4.666666666666667}\n",
      "====================\n",
      "2 正在评估问题：在针对轻量级模型的“强到弱蒸馏”管道中，在线蒸馏（Online Distillation）阶段的具体实现方式是什么？\n",
      "--------------------\n",
      "{'scores': {'Correctness': 1, 'Completeness': 1, 'Clarity & Conciseness': 4}, 'reasoning': '生成答案声称在线蒸馏阶段涉及学生模型生成在线序列并与教师模型logits对齐，但根据正确答案，文档并未提供在线蒸馏的具体实现方式。因此，生成答案的内容与正确答案相悖，存在严重错误，导致正确性和完整性得分极低。表达上较为清晰，但内容完全偏离事实，仅在语言层面保持了一定质量。', 'final_score': 2.0}\n",
      "====================\n",
      "3 正在评估问题：Qwen3的开发团队在预训练数据筛选和模型后训练阶段，具体实施了哪些伦理审查（Ethical Review）流程来确保模型的安全性并减少偏见？\n",
      "--------------------\n",
      "{'scores': {'Correctness': 5, 'Completeness': 1, 'Clarity & Conciseness': 5}, 'reasoning': '生成答案正确复现了【正确答案】的核心结论（无法回答），因此在正确性上得5分。然而，生成答案未包含【正确答案】中明确指出的‘文档中未提及具体伦理审查流程’这一关键信息，导致完整性严重缺失，故完整性得1分。生成答案语言简洁且无冗余，逻辑清晰，因此清晰简洁性得5分。', 'final_score': 3.6666666666666665}\n",
      "====================\n",
      "4 正在评估问题：与Qwen2.5-MoE相比，Qwen3的MoE模型在架构设计上引入了哪些关键的改变？\n",
      "--------------------\n",
      "{'scores': {'Correctness': 3, 'Completeness': 1, 'Clarity & Conciseness': 5}, 'reasoning': '生成答案正确指出了Qwen3-MoE移除共享专家和采用全局批处理负载平衡损失两个关键点，但完全遗漏了细粒度专家分割和激活参数优化这两个核心改进。虽然已提及内容与正确答案一致，但缺失超过半数关键信息，导致正确性和完整性严重不足。语言表达简洁清晰，无冗余或歧义。', 'final_score': 3.0}\n",
      "====================\n",
      "5 正在评估问题：在“思考模式融合”阶段，Qwen3模型是如何通过显式训练（explicitly trained）来学习并实现“思考预算（Thinking Budget）”这一能力的？\n",
      "--------------------\n",
      "{'scores': {'Correctness': 1, 'Completeness': 1, 'Clarity & Conciseness': 5}, 'reasoning': \"生成答案未正确回答问题，与正确答案的核心观点相悖（正确答案明确指出能力非显式训练获得，而生成答案直接表示无法回答），因此正确性得1分。生成答案未包含正确答案中的任何关键信息点（如'非显式训练'和'思考模式融合的自然结果'），完整性得1分。语言表达简洁清晰，无冗余或结构问题，因此清晰简洁性得5分。\", 'final_score': 2.3333333333333335}\n",
      "====================\n",
      "6 正在评估问题：相较于以往的多阶段训练框架（如GTE、E5），Qwen3 Embedding系列在训练流程中引入了哪三项关键创新？\n",
      "--------------------\n",
      "{'scores': {'Correctness': 5, 'Completeness': 5, 'Clarity & Conciseness': 4}, 'reasoning': \"生成答案在语义上与正确答案完全等价，准确复述了三项创新技术的核心要点，包括合成数据驱动训练、高质量数据微调和模型合并技术。所有关键信息点均完整覆盖，且表述逻辑清晰。语言表达稍显学术化但无冗余，第三点的'鲁棒性和泛化性'表述比原文略简略，但未影响核心信息传递。\", 'final_score': 4.666666666666667}\n",
      "====================\n",
      "7 正在评估问题：Qwen3的重排序模型和嵌入模型采用了相同的两阶段训练流程，请解释在第一阶段的弱监督训练中，重排序模型是如何利用合成数据进行优化的？\n",
      "--------------------\n",
      "{'scores': {'Correctness': 1, 'Completeness': 1, 'Clarity & Conciseness': 1}, 'reasoning': \"生成答案完全未尝试回答问题，直接声明'无法回答该问题'，与正确答案的核心信息（弱监督训练阶段使用合成数据）完全无关。未包含任何正确答案的关键信息点，且未提供任何有效解释或推理过程。语言虽然简洁但完全缺乏实质内容，无法满足基本回答要求。\", 'final_score': 1.0}\n",
      "====================\n",
      "8 正在评估问题：请详细描述附录A.1中提到的，为合成检索文本对所采用的两阶段生成流程（配置阶段和查询生成阶段）的具体步骤和目的。\n",
      "--------------------\n",
      "{'scores': {'Correctness': 5, 'Completeness': 5, 'Clarity & Conciseness': 5}, 'reasoning': '生成答案准确复现了正确答案的核心要素：配置阶段通过LLM选择角色/类型/难度配置以增强多样性，查询生成阶段基于配置生成定制化查询。所有关键信息点（五个候选角色、多维度约束、两阶段目的）均完整覆盖，语言表述专业且结构清晰，未出现冗余或歧义。', 'final_score': 5.0}\n",
      "====================\n",
      "9 正在评估问题：Qwen3的重排序模型是如何将相似性评估构建为一个分类问题，并最终计算出相关性分数的？请描述其具体机制和数学表达式。\n",
      "--------------------\n",
      "{'scores': {'Correctness': 5, 'Completeness': 4, 'Clarity & Conciseness': 4}, 'reasoning': '生成答案准确捕捉了正确答案的核心机制：将相似性评估转化为二元分类问题，并通过softmax类函数计算相关性分数。数学表达式完全一致，但未明确提及输入模板的具体格式（如固定指令模板）和概率计算的上下文条件（I,q,d）。语言表述简洁清晰，但可进一步优化公式排版以增强可读性。', 'final_score': 4.333333333333333}\n",
      "====================\n",
      "10 正在评估问题：报告强调了使用Qwen3 32B模型合成大规模训练数据，请问在数据合成过程中，团队遵循了哪些具体的伦理准则或偏见缓解措施来确保生成数据的公平性和无害性？\n",
      "--------------------\n",
      "{'scores': {'Correctness': 5, 'Completeness': 4, 'Clarity & Conciseness': 4}, 'reasoning': \"生成答案正确指出文档未提供相关信息，与正确答案的核心语义一致。但在完整性上略逊于正确答案，未明确说明'未提及伦理准则'这一关键前提，仅以无法回答概括。语言表达简洁清晰，但可进一步优化表述逻辑。\", 'final_score': 4.333333333333333}\n",
      "====================\n",
      "最终得分：3.50\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "从结果可以看出，RAG最终的评分为：3.50分（满分5分）",
   "id": "4da5504f58355973"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
